{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MAbuTalha/Neural-Machine-Translation-NMT-/blob/main/Machine_Translation_Word_level_model_(English_to_Urdu).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Onf8XEcJYBCm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, json, re, sys, time, os\n",
    "from string import digits\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "from config_translator import general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home2/data/\"\n",
    "project_path = \"/home/mateusz/projects/Neural-Machine-Translation-NMT-/\"\n",
    "test_path=project_path + \"dataset/test.json\"\n",
    "train_path=project_path + \"dataset/test.json\"\n",
    "glove = {\n",
    "    \"word_embedings_path\": data_path + \"images/glove/glove.6B.200d.txt\",\n",
    "    \"embedings_dim\": 199\n",
    "}\n",
    "config = {\n",
    "    \"dataset_name\": \"coco14\",\n",
    "    \"config_name\": \"coco14\",\n",
    "    \"results_dir\": project_path + \"results/\",\n",
    "    \"pickles_dir\": \"/Pickle\",\n",
    "    \"coco-caption_path\": \"./coco-caption\"\n",
    "}\n",
    "EMBEDDING_SIZE = glove[\"embedings_dim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    with open(path, 'r') as f:\n",
    "        train_dataset = json.load(f)\n",
    "\n",
    "    bbox_categories_list = []\n",
    "    output_sentences_list = []\n",
    "    output_sentences_per_image_list = []\n",
    "    image_id_list = []\n",
    "    for pair in train_dataset:\n",
    "        bbox_categories = pair[\"bbox_categories\"]\n",
    "        image_id = pair['image_id']\n",
    "        bbox_categories = ' '.join(map(str, bbox_categories))\n",
    "        output_sentences = pair[\"captions\"]\n",
    "        output_sentences_per_image_list.append(output_sentences)\n",
    "        for sentence in output_sentences:\n",
    "            output_sentences_list.append(sentence)\n",
    "            bbox_categories_list.append(bbox_categories)\n",
    "            image_id_list.append(image_id)\n",
    "    return image_id_list, bbox_categories_list, output_sentences_list, output_sentences_per_image_list\n",
    "\n",
    "def clear(lines):\n",
    "    # Lowercase all characters\n",
    "    lines.eng=lines.eng.apply(lambda x: x.lower())\n",
    "    lines.urdu=lines.urdu.apply(lambda x: x.lower())\n",
    "\n",
    "    # Remove quotes\n",
    "    lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x))\n",
    "    lines.urdu=lines.urdu.apply(lambda x: re.sub(\"'\", '', x))\n",
    "\n",
    "    exclude = set(string.punctuation) # Set of all special characters\n",
    "\n",
    "    # Remove all the special characters\n",
    "    lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "    lines.urdu=lines.urdu.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "\n",
    "    # Remove all numbers from text\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "    # Remove extra spaces\n",
    "    lines.eng=lines.eng.apply(lambda x: x.strip())\n",
    "    lines.urdu=lines.urdu.apply(lambda x: x.strip())\n",
    "    lines.eng=lines.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "    lines.urdu=lines.urdu.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "\n",
    "    # Add start and end tokens to target sequences\n",
    "    lines.urdu = lines.urdu.apply(lambda x : 'START_ '+ x + ' _END')\n",
    "    print(\"Sample clean lines\")\n",
    "    print(lines.sample(10))\n",
    "    return lines\n",
    "\n",
    "def define_vocabulary(lines):\n",
    "\n",
    "    # Vocabulary of English\n",
    "    all_eng_words=set()\n",
    "    for eng in lines.eng:\n",
    "        for word in eng.split():\n",
    "            if word not in all_eng_words:\n",
    "                all_eng_words.add(word)\n",
    "\n",
    "    # Vocabulary of Urdu\n",
    "    all_urdu_words=set()\n",
    "    for urdu in lines.urdu:\n",
    "        for word in urdu.split():\n",
    "            if word not in all_urdu_words:\n",
    "                all_urdu_words.add(word)\n",
    "\n",
    "    return all_eng_words, all_urdu_words\n",
    "\n",
    "# Max Length of source sequence\n",
    "def max_src_trg_length(lines):\n",
    "    lenght_list=[]\n",
    "    for l in lines.eng:\n",
    "        lenght_list.append(len(l.split(' ')))\n",
    "    max_length_src = np.max(lenght_list)\n",
    "    print('Max Source Length:',max_length_src)\n",
    "\n",
    "    # Max Length of target sequence\n",
    "    lenght_list=[]\n",
    "    for l in lines.urdu:\n",
    "        lenght_list.append(len(l.split(' ')))\n",
    "    max_length_tar = np.max(lenght_list)\n",
    "    print('Max Target Lenght:',max_length_tar)\n",
    "    return max_length_src, max_length_tar\n",
    "\n",
    "def input_trg_words(all_eng_words, all_urdu_words):\n",
    "    input_words = sorted(list(all_eng_words))\n",
    "    target_words = sorted(list(all_urdu_words))\n",
    "    num_encoder_tokens = len(all_eng_words)+1\n",
    "    num_decoder_tokens = len(all_urdu_words)+1\n",
    "    num_encoder_tokens, num_decoder_tokens\n",
    "    return input_words, target_words, num_encoder_tokens, num_decoder_tokens\n",
    "\n",
    "def reverse_index(input_words, target_words, lines):\n",
    "    input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "    target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "\n",
    "    reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "    reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())\n",
    "\n",
    "    lines = shuffle(lines)\n",
    "    print(\"Shuffled lines\")\n",
    "    lines.head(10)\n",
    "    return input_token_index, target_token_index, reverse_input_char_index, reverse_target_char_index\n",
    "\n",
    "def get_embedding_matrix(vocab_size, wordtoix, word_embedings_path, embedings_dim):\n",
    "    def isfloat(value):\n",
    "        try:\n",
    "            float(value)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "    embeddings_index = {}\n",
    "    # From the embeddings matrix get coefficients of particular words and store the in dictionarym by key - words\n",
    "    f = open(word_embedings_path, encoding=\"utf-8\")\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        import re\n",
    "        if isfloat(values[1]):\n",
    "            coefs = np.asarray(values[2:], dtype='float32')\n",
    "        elif isfloat(values[2]):\n",
    "            coefs = np.asarray(values[3:], dtype='float32')\n",
    "        elif isfloat(values[3]):\n",
    "            coefs = np.asarray(values[4:], dtype='float32')\n",
    "        elif isfloat(values[4]):\n",
    "            coefs = np.asarray(values[5:], dtype='float32')\n",
    "        else:\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "    # Get 200-dim/100 dense vector for each of the 10000 words in out vocabulary\n",
    "    embedding_matrix = np.zeros((vocab_size, embedings_dim))\n",
    "    for word, i in wordtoix.items():\n",
    "        # if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in the embedding index will be all zeros\n",
    "            # 1655,299 199\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    print(\"Shape of embedding matrix\")\n",
    "    print(embedding_matrix.shape)\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                            image_id          eng  \\\n",
      "0       COCO_train2014_000000406533  person skis   \n",
      "1       COCO_train2014_000000406533  person skis   \n",
      "2       COCO_train2014_000000406533  person skis   \n",
      "3       COCO_train2014_000000406533  person skis   \n",
      "4       COCO_train2014_000000406533  person skis   \n",
      "...                             ...          ...   \n",
      "561895  COCO_train2014_000000378868          dog   \n",
      "561896  COCO_train2014_000000378868          dog   \n",
      "561897  COCO_train2014_000000378868          dog   \n",
      "561898  COCO_train2014_000000378868          dog   \n",
      "561899  COCO_train2014_000000378868          dog   \n",
      "\n",
      "                                                     urdu  \n",
      "0                Someone is standing in the snow on skies  \n",
      "1           The skier wearing an orange jacket is waving.  \n",
      "2       A female skier is waving and smiling for the c...  \n",
      "3       a female snow skier in an orange jacket waving...  \n",
      "4           a woman is smiling while on skies in the snow  \n",
      "...                                                   ...  \n",
      "561895   A black and white dog playing in the ocean foam.  \n",
      "561896         a dog is playing near the water on a beach  \n",
      "561897  A black and white dog eating a fish out of the...  \n",
      "561898         A black and white dog on shore of a beach.  \n",
      "561899  A dog playing in the surf at the edge of the b...  \n",
      "\n",
      "[561900 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "image_id_list, bbox_categories_list_train, output_sentences_list_train, _ = load_dataset(train_path)\n",
    "lines=pd.DataFrame({'image_id': pd.Series(image_id_list), 'eng': pd.Series(bbox_categories_list_train), 'urdu':pd.Series(output_sentences_list_train)})\n",
    "print(lines.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample clean lines\n",
      "                           image_id  \\\n",
      "311948  COCO_train2014_000000037282   \n",
      "80303   COCO_train2014_000000163220   \n",
      "193209  COCO_train2014_000000564339   \n",
      "515940  COCO_train2014_000000054850   \n",
      "391976  COCO_train2014_000000441232   \n",
      "459216  COCO_train2014_000000210570   \n",
      "155821  COCO_train2014_000000110310   \n",
      "516551  COCO_train2014_000000310732   \n",
      "222252    COCO_val2014_000000012413   \n",
      "277660    COCO_val2014_000000115222   \n",
      "\n",
      "                                                      eng  \\\n",
      "311948                    tie person person cake fork cup   \n",
      "80303   potted plant potted plant horse car car car bu...   \n",
      "193209                                             person   \n",
      "515940                              person person frisbee   \n",
      "391976                                               sink   \n",
      "459216                                       person bench   \n",
      "155821                                           airplane   \n",
      "516551                                   person surfboard   \n",
      "222252  snowboard person person person person person p...   \n",
      "277660                car car car truck car car stop sign   \n",
      "\n",
      "                                                     urdu  \n",
      "311948  START_ a couple on there wedding day standing ...  \n",
      "80303   START_ a horse drawn carriage with three men r...  \n",
      "193209  START_ a woman crosscounty skiing on a path in...  \n",
      "515940  START_ two boys who are standing in the grass ...  \n",
      "391976  START_ this is a cream colored tiled bathroom ...  \n",
      "459216  START_ someone sitting on a bench between two ...  \n",
      "155821  START_ an image of a plane taking off in the a...  \n",
      "516551  START_ a person playing on the water with the ...  \n",
      "222252       START_ a couple of people on a ski lift _END  \n",
      "277660  START_ the back of a stop sign on a city stree...  \n"
     ]
    }
   ],
   "source": [
    "lines = clear(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Source Length: 106\n",
      "Max Target Lenght: 51\n"
     ]
    }
   ],
   "source": [
    "all_eng_words, all_urdu_words = define_vocabulary(lines)\n",
    "max_length_src, max_length_tar = max_src_trg_length(lines)\n",
    "input_words, target_words, num_encoder_tokens, num_decoder_tokens = input_trg_words(all_eng_words, all_urdu_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled lines\n"
     ]
    }
   ],
   "source": [
    "num_decoder_tokens += 1 # For zero padding\n",
    "num_decoder_tokens\n",
    "input_token_index, target_token_index, reverse_input_char_index,reverse_target_char_index = reverse_index(input_words, target_words, lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "Shape of embedding matrix\n",
      "(93, 199)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix_input = get_embedding_matrix(num_encoder_tokens, input_token_index,\n",
    "                                                   glove[\"word_embedings_path\"],\n",
    "                                                   EMBEDDING_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6I3jdPSgy5Su"
   },
   "source": [
    "**Creating training and test dataset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5ngV0e8cMGR",
    "outputId": "85e1114a-8aca-4a7e-b143-b1627c2d8651"
   },
   "outputs": [],
   "source": [
    "# Train - Test Split\n",
    "X, y = lines.eng, lines.urdu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DiFwOxV9cMDg"
   },
   "outputs": [],
   "source": [
    "#Save the train and test dataframes for reproducing the results later, as they are shuffled.\n",
    "\n",
    "X.to_pickle('X_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7xcAcM-vcL4o"
   },
   "outputs": [],
   "source": [
    "def generate_batch(X, y, input_token_index, target_token_index,max_length_src, max_length_tar, batch_size = 64 ):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 17:25:25.258984: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-01 17:25:25.261000: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "train_samples = len(X)\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "latent_dim = 256\n",
    "print(train_samples//batch_size)\n",
    "# Encoder\n",
    "encoder_inputs =  Input(shape=(max_length_src,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, EMBEDDING_SIZE, weights=[embedding_matrix_input], input_length=max_length_src,)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(max_length_tar,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4hRLXQCXdH1I"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UQHwZGgudTLY",
    "outputId": "7ece987e-8158-47a9-94cb-dc22c2a8b3e2"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss', min_delta=0.001, patience=3)\n",
    "filepath = config[\"results_dir\"] + 'model_Base_3_Batch_Komninos.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True,\n",
    "                             mode='min', save_weights_only=False)\n",
    "callbacks_list = [checkpoint, es, CSVLogger(config[\"results_dir\"] +'logs.csv',\n",
    "                                            separator=\",\", append=True),]\n",
    "batch_generator = generate_batch(X, y, input_token_index, target_token_index, max_length_src, max_length_tar, batch_size = batch_size)\n",
    "model.fit(batch_generator,\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[callbacks_list], verbose=1\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "bGoxmP2Oig5T"
   },
   "outputs": [],
   "source": [
    "#Always remember to save the weights\n",
    "\n",
    "model.save_weights('model_Base_3_Batch_Komninos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "d7g55h0Yiqbj"
   },
   "outputs": [],
   "source": [
    "#Load the weights, if you close the application\n",
    "model.load_weights(config[\"results_dir\"] + 'model_Base_3_Batch_Komninos.h5')\n",
    "#Inference Setup\n",
    "\n",
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4939gUQiqYz"
   },
   "outputs": [],
   "source": [
    "**Evaluation on Validation Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decode sample sequeces\n",
    "def decode_sequence(input_seq, encoder_model, decoder_model, target_token_index, reverse_target_char_index):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WFTGMBMxjyfV",
    "outputId": "3828723f-654e-4284-a525-60d0dd9e5f08"
   },
   "outputs": [],
   "source": [
    "def load_dataset_test(path):\n",
    "    with open(path, 'r') as f:\n",
    "        train_dataset = json.load(f)\n",
    "        \n",
    "    image_id_list = []\n",
    "    bbox_categories_list = []\n",
    "    output_sentences_per_image_list = []\n",
    "    for pair in train_dataset:\n",
    "        bbox_categories = pair[\"bbox_categories\"]\n",
    "        bbox_categories = ' '.join(map(str, bbox_categories))\n",
    "        bbox_categories_list.append(bbox_categories)\n",
    "        image_id = pair['image_id']\n",
    "        image_id_list.append(image_id)\n",
    "        output_sentences = pair[\"captions\"]\n",
    "        output_sentences_per_image_list.append(output_sentences)\n",
    "    return image_id_list, bbox_categories_list, output_sentences_per_image_list\n",
    "\n",
    "def generate_batch_test(X, input_token_index,max_length_src, batch_size = 64 ):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            for i, input_text in enumerate(X[j:j+batch_size]):\n",
    "                print(input_text)\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "            yield([encoder_input_data])\n",
    "\n",
    "def prepare_for_evaluation(lines, test_val_gen, encoder_model, decoder_model, target_token_index, reverse_target_char_index):\n",
    "    img_id, X_test, actual_sentences = lines.image_id, lines.eng, lines.actual_sentences\n",
    "    # Get all image-ids from test dataset\n",
    "    expected = dict()\n",
    "    results = dict()\n",
    "    print(\"Preparing for evaluation\")\n",
    "    # calculation of metrics for test images dataset\n",
    "    k = -1\n",
    "    index_rows_process = 0\n",
    "    for pair in range(0, len(lines)):\n",
    "        k+=1\n",
    "        image_id = img_id[k:k+1].values[0]\n",
    "        expected[image_id] = []\n",
    "        # Put ground truth captions to the structure accepted by evaluation framework.\n",
    "        for desc in actual_sentences[k:k+1].values[0]:\n",
    "            expected[image_id].append({\"image_id\": image_id, \"caption\": desc})\n",
    "        # Predict captions\n",
    "\n",
    "        st = time.time()\n",
    "        \n",
    "        (input_seq) = next(test_val_gen)\n",
    "        decoded_sentence = decode_sequence(input_seq, encoder_model, decoder_model, target_token_index, reverse_target_char_index)\n",
    "        generated = decoded_sentence.replace(\" _END\", \"\")\n",
    "        input_sequence = X_test[k:k+1].values[0]\n",
    "        et = time.time()\n",
    "        # get the execution time\n",
    "        elapsed_time = et - st\n",
    "\n",
    "        # get the execution time\n",
    "        # Put predicted captions to the structure accepted by evaluation framework.\n",
    "        results[image_id] = [{\"image_id\": image_id, \"caption\": generated, \"time\": elapsed_time}]\n",
    "        if index_rows_process % 100 == 0:\n",
    "            print(\"Processed:\")\n",
    "            print(index_rows_process)\n",
    "            print('Execution time:', elapsed_time * 1000, 'miliseconds')\n",
    "            print(\"input_sequence\", input_sequence)\n",
    "            print(\"generated\", generated)\n",
    "            print(\"saved\")\n",
    "        index_rows_process += 1\n",
    "    return expected, results\n",
    "\n",
    "def clear_test(lines):\n",
    "    # Lowercase all characters\n",
    "    lines.eng=lines.eng.apply(lambda x: x.lower())\n",
    "    # Remove quotes\n",
    "    lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x))\n",
    "    exclude = set(string.punctuation) # Set of all special characters\n",
    "\n",
    "    # Remove all the special characters\n",
    "    lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "\n",
    "    # Remove all numbers from text\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "    # Remove extra spaces\n",
    "    lines.eng=lines.eng.apply(lambda x: x.strip())\n",
    "    lines.eng=lines.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "    lines.sample(10)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing for evaluation\n",
      "cat cat\n",
      "Processed:\n",
      "0\n",
      "Execution time: 3733.4823608398438 miliseconds\n",
      "input_sequence cat cat\n",
      "generated  a cat is looking at the camera with a cat\n",
      "saved\n",
      "clock\n",
      "boat boat boat boat boat boat boat boat boat boat person\n",
      "train\n",
      "sheep sheep sheep sheep sheep sheep sheep sheep sheep sheep sheep sheep truck sheep sheep\n",
      "tv couch bowl vase bowl vase vase potted plant\n",
      "dog car motorcycle motorcycle\n",
      "horse horse person person horse\n",
      "surfboard person\n",
      "person frisbee\n",
      "person person surfboard surfboard\n",
      "person\n",
      "pizza cat person chair dining table\n",
      "car person person car car bus\n",
      "cat couch dining table dog bowl bowl chair mouse\n",
      "bird bird bird bird bird bird bird bird bird bird bird bird bird bird bird bird bird bird bird bird bird bird bird person bird bird bird\n",
      "person person person person surfboard person person\n",
      "car car car car car car fire hydrant fire hydrant car car car car stop sign car\n",
      "person kite kite\n",
      "person person snowboard bottle\n",
      "person kite\n",
      "sandwich carrot carrot carrot carrot carrot\n",
      "elephant\n",
      "person surfboard surfboard\n",
      "tie person person person person person person person person person person\n",
      "sandwich bowl dining table wine glass sandwich\n",
      "motorcycle motorcycle motorcycle person motorcycle motorcycle motorcycle motorcycle person person motorcycle motorcycle\n",
      "surfboard surfboard surfboard surfboard person person person person person surfboard person person\n",
      "bird giraffe\n",
      "chair person person laptop handbag handbag handbag\n",
      "bottle bottle sandwich person knife\n",
      "train person umbrella handbag\n",
      "sports ball person tennis racket\n",
      "train stop sign\n",
      "traffic light traffic light traffic light car\n",
      "bottle sandwich sandwich keyboard laptop\n",
      "person surfboard\n",
      "bird bird car car\n",
      "bed teddy bear\n",
      "cell phone person person suitcase\n",
      "person person frisbee person\n",
      "pizza dining table\n",
      "sink cup cup\n",
      "dog person sports ball baseball glove dog\n",
      "chair chair couch couch couch wine glass vase vase vase person backpack wine glass wine glass wine glass tv vase bottle wine glass cup book\n",
      "cat book bed\n",
      "fire hydrant\n",
      "person remote\n",
      "toothbrush person\n",
      "bed person chair\n",
      "bird bird bird bird bird bird\n",
      "umbrella person person person person person person person person person person person person\n",
      "person person skateboard\n",
      "tie tie tie tie tie tie tie tie\n",
      "sheep\n",
      "bird bird cat chair\n",
      "person person person person person person person person person person sports ball person person baseball glove baseball glove person person\n",
      "person person orange orange orange orange truck apple apple apple apple orange orange orange orange orange carrot carrot carrot\n",
      "refrigerator microwave chair chair dining table clock oven bottle bottle\n",
      "cow cow cow cow cow cow cow cow\n",
      "person surfboard\n",
      "bear bear\n",
      "bird bird bird bird bird bird bird elephant elephant elephant elephant elephant bird bird elephant elephant bird\n",
      "bed person teddy bear teddy bear\n",
      "bird clock\n",
      "car car bus person person person person person car car car car handbag\n",
      "person person person person elephant bench\n",
      "bicycle bicycle bicycle person truck truck person person person person person person person bicycle bicycle bicycle bicycle bicycle bus car car\n",
      "car fire hydrant\n",
      "person person person person person backpack person person person bicycle cell phone person backpack backpack person\n",
      "train person person person person person person cell phone handbag handbag person person person person person person handbag person\n",
      "clock person person person backpack person\n",
      "knife banana\n",
      "sheep sheep sheep sheep sheep sheep sheep sheep sheep sheep sheep sheep sheep sheep\n",
      "person person person person person person person person bus bus bus backpack backpack person\n",
      "sports ball person person person baseball bat baseball glove bench person person\n",
      "person person person person person person sports ball baseball glove person person person person person person person person\n",
      "umbrella traffic light person person person handbag truck\n",
      "bottle couch dining table wine glass broccoli broccoli broccoli book book broccoli broccoli broccoli broccoli broccoli broccoli broccoli broccoli broccoli\n",
      "bicycle person cup cup person cup\n",
      "person person person person person person person elephant elephant person person person person person person person\n",
      "horse horse car bus person person clock person horse person\n",
      "person skateboard\n",
      "cow cow cow\n",
      "sports ball person tennis racket chair person\n",
      "sports ball person person tennis racket\n",
      "car car truck bus truck\n",
      "dog boat person person\n",
      "sports ball person person tennis racket\n",
      "toilet\n",
      "car person person person person bus person car person person person person person person person car\n",
      "clock\n",
      "person surfboard\n",
      "car boat boat boat\n",
      "bottle bottle bottle bottle bottle remote bottle\n",
      "dog person backpack parking meter bicycle\n",
      "spoon bowl carrot broccoli carrot\n",
      "stop sign car car car car car car car car car car car car car car\n",
      "person person surfboard surfboard person kite kite kite kite kite person person person person person person person person person person\n",
      "sheep sheep sheep sheep sheep\n"
     ]
    }
   ],
   "source": [
    "image_id_list, bbox_categories_list, output_sentences_per_image_list = load_dataset_test(test_path) \n",
    "lines=pd.DataFrame({'image_id': pd.Series(image_id_list),\n",
    "                    'eng': pd.Series(bbox_categories_list),\n",
    "                    'actual_sentences': pd.Series(output_sentences_per_image_list)})\n",
    "lines=lines[0:100]\n",
    "lines = clear_test(lines)\n",
    "img_id, X_test, actual_sentences = lines.image_id, lines.eng, lines.actual_sentences\n",
    "test_val_gen = generate_batch_test(X_test, input_token_index,max_length_src,1)\n",
    "    \n",
    "expected, results = prepare_for_evaluation(lines, test_val_gen, encoder_model, decoder_model, target_token_index, reverse_target_char_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_results(expected, results, config):\n",
    "    sys.path.append(config[\"coco-caption_path\"])\n",
    "    from pycocoevalcap.eval_any import COCOEvalCap\n",
    "    # Load expected captions(ground truth from dataset) and results(predicted captions for specific image)\n",
    "    # to the evaluation framework\n",
    "    cocoEvalObj = COCOEvalCap(expected, results)\n",
    "    # Evaluate\n",
    "    cocoEvalObj.evaluate()\n",
    "    calculated_metrics = {}\n",
    "    # Store metrics  values in dictionary by metrics names\n",
    "    for metric, score in cocoEvalObj.eval.items():\n",
    "        calculated_metrics[metric] = score\n",
    "    print(calculated_metrics)\n",
    "    print(\"Calculating final results\")\n",
    "    imgToEval = cocoEvalObj.imgToEval\n",
    "    for p in results:\n",
    "        print(imgToEval)\n",
    "        image_id, caption = p, results[p][0]['caption']\n",
    "        imgToEval[image_id]['caption'] = caption\n",
    "        imgToEval[image_id]['ground_truth_captions'] = [x['caption'] for x in expected[p]]\n",
    "\n",
    "    evaluation_results_save_path = os.path.join(config[\"results_dir\"], config[\"config_name\"] + '.json')\n",
    "    print(\"Results saved to \")\n",
    "    print(evaluation_results_save_path)\n",
    "    # Path to save evaluation results\n",
    "    with open(evaluation_results_save_path, 'w') as outfile:\n",
    "        json.dump(\n",
    "            {'overall': calculated_metrics, 'dataset_name': config[\"results_dir\"], 'imgToEval': imgToEval},\n",
    "            outfile)\n",
    "    return calculated_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 6233 tokens at 41259.68 tokens per second.\n",
      "PTBTokenizer tokenized 1083 tokens at 12620.42 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 984, 'reflen': 976, 'guess': [984, 884, 784, 684], 'correct': [686, 318, 135, 66]}\n",
      "ratio: 1.0081967213104424\n",
      "Bleu_1: 0.697\n",
      "Bleu_2: 0.501\n",
      "Bleu_3: 0.351\n",
      "Bleu_4: 0.254\n",
      "computing METEOR score...\n",
      "METEOR: 0.232\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.502\n",
      "computing CIDEr score...\n",
      "CIDEr: 1.000\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/mateusz/projects/Neural-Machine-Translation-NMT-/coco-caption/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Threads( StanfordCoreNLP ) [8.35 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [1.29 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.66 s\n",
      "SPICE: 0.160\n",
      "computing WMD score...\n",
      "WMD: 0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Bleu_1': 0.697154471544007,\n",
       " 'Bleu_2': 0.5007857196929164,\n",
       " 'Bleu_3': 0.3508384573128562,\n",
       " 'Bleu_4': 0.25406939473136414,\n",
       " 'METEOR': 0.2317892761903464,\n",
       " 'ROUGE_L': 0.5018448559292853,\n",
       " 'CIDEr': 1.0002175832894291,\n",
       " 'SPICE': 0.16029502317110267,\n",
       " 'WMD': 0.49810717709173324}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_results(expected, results, config)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN6QCPXRCqxPt3n0lPPwRqC",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Machine Translation  Word-level model (English to Urdu).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "framework",
   "language": "python",
   "name": "framework"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}